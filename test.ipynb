{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "dataloader.py"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading raw file: ./data/test_32x32.mat\n",
      "filling input queue\n",
      "loading batch of samples: 100\n",
      "DATALOADER ERROR: Enqueue operation was cancelled\n",
      "\t [[Node: fifo_queue_EnqueueMany = QueueEnqueueManyV2[Tcomponents=[DT_INT64, DT_INT64], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](fifo_queue, _recv_input_images_0, _recv_input_labels_0)]]\n",
      "\n",
      "Caused by op u'fifo_queue_EnqueueMany', defined at:\n",
      "  File \"/usr/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\n",
      "    \"__main__\", fname, loader, pkg_name)\n",
      "  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n",
      "    exec code in run_globals\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n",
      "    ioloop.IOLoop.instance().start()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n",
      "    super(ZMQIOLoop, self).start()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py\", line 887, in start\n",
      "    handler_func(fd_obj, events)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-5-51b691a25abb>\", line 148, in <module>\n",
      "    dataloader = DataLoader(VALID_DATASET_PATH, BATCH_SIZE)\n",
      "  File \"<ipython-input-5-51b691a25abb>\", line 50, in __init__\n",
      "    self.enqueue = self.example_queue.enqueue_many([self.queue_image, self.queue_label])\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/data_flow_ops.py\", line 367, in enqueue_many\n",
      "    self._queue_ref, vals, name=scope)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 1538, in _queue_enqueue_many_v2\n",
      "    name=name)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\n",
      "    op_def=op_def)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2327, in create_op\n",
      "    original_op=self._default_original_op, op_def=op_def)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1226, in __init__\n",
      "    self._traceback = _extract_stack()\n",
      "\n",
      "CancelledError (see above for traceback): Enqueue operation was cancelled\n",
      "\t [[Node: fifo_queue_EnqueueMany = QueueEnqueueManyV2[Tcomponents=[DT_INT64, DT_INT64], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](fifo_queue, _recv_input_images_0, _recv_input_labels_0)]]\n",
      "\n",
      "INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.CancelledError'>, Enqueue operation was cancelled\n",
      "\t [[Node: fifo_queue_EnqueueMany = QueueEnqueueManyV2[Tcomponents=[DT_INT64, DT_INT64], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](fifo_queue, _recv_input_images_0, _recv_input_labels_0)]]\n",
      "\n",
      "Caused by op u'fifo_queue_EnqueueMany', defined at:\n",
      "  File \"/usr/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\n",
      "    \"__main__\", fname, loader, pkg_name)\n",
      "  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n",
      "    exec code in run_globals\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n",
      "    ioloop.IOLoop.instance().start()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n",
      "    super(ZMQIOLoop, self).start()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py\", line 887, in start\n",
      "    handler_func(fd_obj, events)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-5-51b691a25abb>\", line 148, in <module>\n",
      "    dataloader = DataLoader(VALID_DATASET_PATH, BATCH_SIZE)\n",
      "  File \"<ipython-input-5-51b691a25abb>\", line 50, in __init__\n",
      "    self.enqueue = self.example_queue.enqueue_many([self.queue_image, self.queue_label])\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/data_flow_ops.py\", line 367, in enqueue_many\n",
      "    self._queue_ref, vals, name=scope)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 1538, in _queue_enqueue_many_v2\n",
      "    name=name)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\n",
      "    op_def=op_def)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2327, in create_op\n",
      "    original_op=self._default_original_op, op_def=op_def)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1226, in __init__\n",
      "    self._traceback = _extract_stack()\n",
      "\n",
      "CancelledError (see above for traceback): Enqueue operation was cancelled\n",
      "\t [[Node: fifo_queue_EnqueueMany = QueueEnqueueManyV2[Tcomponents=[DT_INT64, DT_INT64], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](fifo_queue, _recv_input_images_0, _recv_input_labels_0)]]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data stream closed.\n",
      "thread error:  Enqueue operation was cancelled\n",
      "\t [[Node: fifo_queue_EnqueueMany = QueueEnqueueManyV2[Tcomponents=[DT_INT64, DT_INT64], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](fifo_queue, _recv_input_images_0, _recv_input_labels_0)]]\n",
      "\n",
      "Caused by op u'fifo_queue_EnqueueMany', defined at:\n",
      "  File \"/usr/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\n",
      "    \"__main__\", fname, loader, pkg_name)\n",
      "  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n",
      "    exec code in run_globals\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n",
      "    ioloop.IOLoop.instance().start()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n",
      "    super(ZMQIOLoop, self).start()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py\", line 887, in start\n",
      "    handler_func(fd_obj, events)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-5-51b691a25abb>\", line 148, in <module>\n",
      "    dataloader = DataLoader(VALID_DATASET_PATH, BATCH_SIZE)\n",
      "  File \"<ipython-input-5-51b691a25abb>\", line 50, in __init__\n",
      "    self.enqueue = self.example_queue.enqueue_many([self.queue_image, self.queue_label])\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/data_flow_ops.py\", line 367, in enqueue_many\n",
      "    self._queue_ref, vals, name=scope)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 1538, in _queue_enqueue_many_v2\n",
      "    name=name)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\n",
      "    op_def=op_def)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2327, in create_op\n",
      "    original_op=self._default_original_op, op_def=op_def)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1226, in __init__\n",
      "    self._traceback = _extract_stack()\n",
      "\n",
      "CancelledError (see above for traceback): Enqueue operation was cancelled\n",
      "\t [[Node: fifo_queue_EnqueueMany = QueueEnqueueManyV2[Tcomponents=[DT_INT64, DT_INT64], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](fifo_queue, _recv_input_images_0, _recv_input_labels_0)]]\n",
      "\n",
      "dataloader closed successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f74ceda8750>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f74b0b57210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD8CAYAAABekO4JAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f75022daed0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import math\n",
    "import os\n",
    "import threading\n",
    "\n",
    "from six.moves import xrange\n",
    "import scipy.io as sio\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# configuration\n",
    "BATCH_SIZE = 100\n",
    "NUM_SUBPLOT_COLS = 10\n",
    "DATASET_PATH = \"../data/train_32x32.mat\"\n",
    "VALID_DATASET_PATH = \"./data/test_32x32.mat\"\n",
    "GEN_TEST_PATH = \"../data/test_images.mat\"\n",
    "CROP_H = 24\n",
    "CROP_W = 24\n",
    "\n",
    "NUM_CLASSES = 10\n",
    "NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN = 73257\n",
    "NUM_EXAMPLES_PER_EPOCH_FOR_EVAL = 1000\n",
    "\n",
    "class DataLoader:\n",
    "  def __init__(self, data_path, batch_size=50, num_valid_samples=None):\n",
    "    print(\"loading raw file:\", data_path)\n",
    "    data = sio.loadmat(data_path)\n",
    "    self.images = data['X']\n",
    "    self.labels = data['y']\n",
    "    self.images = np.transpose(self.images, (3, 0, 1, 2))\n",
    "    self.labels[self.labels==10] = 0\n",
    "    self.num_valid_samples = num_valid_samples\n",
    "    self.batch_size = num_valid_samples or batch_size\n",
    "    if self.num_valid_samples != None:\n",
    "      self.random_valid_set()\n",
    "    # create queue\n",
    "    print(\"filling input queue\")\n",
    "    self.queue_image = tf.placeholder(tf.int64, shape=[self.batch_size, 32, 32, 3], name=\"input_images\")\n",
    "    self.queue_label = tf.placeholder(tf.int64, shape=[self.batch_size, 1], name=\"input_labels\")\n",
    "    self.example_queue = tf.FIFOQueue(\n",
    "      capacity=int(NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN * 0.4) + 3 * self.batch_size,\n",
    "      dtypes=[tf.int64, tf.int64],\n",
    "      shapes=[[32, 32, 3], [1]])\n",
    "    # self.example_queue = tf.train.input_producer(examples)\n",
    "    self.enqueue = self.example_queue.enqueue_many([self.queue_image, self.queue_label])\n",
    "\n",
    "    self.enqueue_thread = None\n",
    "    self.coord = None\n",
    "    self.coord = tf.train.Coordinator()\n",
    "    self.threads = None\n",
    "\n",
    "  def random_valid_set(self):\n",
    "    num_valid_samples = self.num_valid_samples\n",
    "    dataset_size = self.images.shape[0]\n",
    "    start = np.random.randint(0, dataset_size - num_valid_samples)\n",
    "    self.images = self.images[start:start+num_valid_samples]\n",
    "    self.labels = self.labels[start:start+num_valid_samples]\n",
    "    print(\"random validation set [%d:%d]\" % (start, start+num_valid_samples))\n",
    "    \n",
    "  def data_stream(self, session):\n",
    "    start = 0\n",
    "    dataset_size = len(self.labels)\n",
    "    try:\n",
    "      while not self.coord.should_stop():\n",
    "      # while True:\n",
    "        end = start + self.batch_size\n",
    "        # print(\"loading [%d:%d] into input queue...\" % (start, end))\n",
    "        if end <= dataset_size:\n",
    "          image_batch = self.images[start:end]\n",
    "          label_batch = self.labels[start:end]\n",
    "          start = end\n",
    "        else:\n",
    "          remaining = end - dataset_size\n",
    "          image_batch = np.concatenate((self.images[start:dataset_size], self.images[0:remaining]))\n",
    "          label_batch = np.concatenate((self.labels[start:dataset_size], self.labels[0:remaining]))\n",
    "          start = remaining\n",
    "        session.run(\n",
    "          self.enqueue, \n",
    "          feed_dict={\n",
    "            self.queue_image : image_batch,\n",
    "            self.queue_label : label_batch})\n",
    "    except Exception as e:\n",
    "      print(\"DATALOADER ERROR:\", e)\n",
    "      self.coord.request_stop(e)\n",
    "    print(\"data stream closed.\")\n",
    "\n",
    "  def preprocess(self):\n",
    "    image, label = self.example_queue.dequeue()\n",
    "    # distorted_image = tf.random_crop(image, [CROP_H, CROP_w, 3])\n",
    "    if self.num_valid_samples == None:\n",
    "      distorted_image = tf.image.random_flip_left_right(image)\n",
    "      distorted_image = tf.image.random_brightness(distorted_image, max_delta=63)\n",
    "      distorted_image = tf.image.random_contrast(distorted_image, lower=0.2, upper=1.8)\n",
    "    else:\n",
    "      distorted_image = image\n",
    "    float_image = tf.image.per_image_standardization(distorted_image)\n",
    "    return float_image, label\n",
    "\n",
    "  def load_batch(self):\n",
    "    image, label= self.preprocess()\n",
    "    image.set_shape([32, 32, 3])\n",
    "    label.set_shape([1])\n",
    "    if self.num_valid_samples != None:\n",
    "      image_batch, label_batch = tf.train.shuffle_batch(\n",
    "        [image, label],\n",
    "        batch_size=self.batch_size,\n",
    "        num_threads=4,\n",
    "        capacity=int(NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN * 0.4) + 3 * self.batch_size,\n",
    "        min_after_dequeue=int(NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN * 0.4))\n",
    "    else:\n",
    "      image_batch, label_batch = tf.train.batch(\n",
    "        [image, label],\n",
    "        batch_size=self.batch_size,\n",
    "        num_threads=4,\n",
    "        capacity=int(NUM_EXAMPLES_PER_EPOCH_FOR_EVAL * 0.4) + 3 * self.batch_size)\n",
    "\n",
    "    tf.summary.image('images', image_batch)\n",
    "    print(\"loading batch of samples:\", self.batch_size) \n",
    "    return image_batch, tf.reshape(label_batch, [self.batch_size])\n",
    "\n",
    "  def load(self, session):\n",
    "    self.enqueue_thread = threading.Thread(target=self.data_stream, args=[session])\n",
    "    self.enqueue_thread.isDaemon()\n",
    "    self.enqueue_thread.start()\n",
    "    self.threads = tf.train.start_queue_runners(coord=self.coord, sess=session)\n",
    "    \n",
    "  def close(self, session):\n",
    "    session.run(self.example_queue.close(cancel_pending_enqueues=True))\n",
    "    self.coord.request_stop()\n",
    "    try:\n",
    "      self.coord.join(self.threads)\n",
    "    except Exception as e:\n",
    "      print(\"thread error: \", e)\n",
    "    print(\"dataloader closed successfully.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  fig = plt.figure()\n",
    "  num_plot_cols = NUM_SUBPLOT_COLS\n",
    "  num_plot_rows = int(math.ceil(BATCH_SIZE/num_plot_cols))\n",
    "  labels = []\n",
    "\n",
    "  with tf.Graph().as_default():\n",
    "    dataloader = DataLoader(VALID_DATASET_PATH, BATCH_SIZE)\n",
    "    image_batch, label_batch = dataloader.load_batch()\n",
    "    run_options = tf.RunOptions(timeout_in_ms=4000000)\n",
    "    with tf.Session() as session:\n",
    "      dataloader.load(session)\n",
    "      for epoch in range(NUM_EXAMPLES_PER_EPOCH_FOR_EVAL // BATCH_SIZE):\n",
    "        images, labels = session.run([image_batch, label_batch], options=run_options)\n",
    "        print(images.shape, labels.shape)\n",
    "        print(labels)\n",
    "        for batch_i in range(BATCH_SIZE):\n",
    "          sub_plot = fig.add_subplot(num_plot_rows, num_plot_cols, batch_i+1)\n",
    "          plt.imshow(images[batch_i])\n",
    "      dataloader.close(session)\n",
    "  plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
