{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "dataloader.py"
    ]
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py\", line 61, in <module>\n    from tensorflow.python import pywrap_tensorflow\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py\", line 28, in <module>\n    _pywrap_tensorflow = swig_import_helper()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)\nImportError: libcudart.so.7.5: cannot open shared object file: No such file or directory\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md#import_error\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mImportError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-fc5bba1badfd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# pylint: disable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;31m# pylint: enable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msome\u001b[0m \u001b[0mcommon\u001b[0m \u001b[0mreasons\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msolutions\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mInclude\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mentire\u001b[0m \u001b[0mstack\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m above this error message when asking for help.\"\"\" % traceback.format_exc()\n\u001b[0;32m---> 72\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;31m# Protocol buffers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Traceback (most recent call last):\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py\", line 61, in <module>\n    from tensorflow.python import pywrap_tensorflow\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py\", line 28, in <module>\n    _pywrap_tensorflow = swig_import_helper()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)\nImportError: libcudart.so.7.5: cannot open shared object file: No such file or directory\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md#import_error\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help."
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import math\n",
    "import os\n",
    "import threading\n",
    "\n",
    "from six.moves import xrange\n",
    "import scipy.io as sio\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# configuration\n",
    "BATCH_SIZE = 100\n",
    "NUM_SUBPLOT_COLS = 10\n",
    "DATASET_PATH = \"./data/train_32x32.mat\"\n",
    "\n",
    "NUM_CLASSES = 10\n",
    "NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN = 50000\n",
    "NUM_EXAMPLES_PER_EPOCH_FOR_EVAL = 10000\n",
    "\n",
    "class DataLoader:\n",
    "  def __init__(self, data_path, batch_size=50):\n",
    "    data = sio.loadmat(data_path)\n",
    "    self.batch_size = batch_size\n",
    "    self.images = data['X']\n",
    "    self.labels = data['y']\n",
    "    self.images = np.transpose(self.images, (3, 0, 1, 2))\n",
    "\n",
    "    # fill queue\n",
    "    self.queue_image = tf.placeholder(tf.int64, shape=[self.batch_size, 32, 32, 3])\n",
    "    self.queue_label = tf.placeholder(tf.int64, shape=[self.batch_size, 1])\n",
    "    self.example_queue = tf.FIFOQueue(\n",
    "      capacity=NUM_EXAMPLES_PER_EPOCH_FOR_EVAL + 3 * self.batch_size,\n",
    "      dtypes=[tf.int64, tf.int64],\n",
    "      shapes=[[32, 32, 3], [1]])\n",
    "    # self.example_queue = tf.train.input_producer(examples)\n",
    "    self.enqueue = self.example_queue.enqueue_many([self.queue_image, self.queue_label])\n",
    "\n",
    "    self.enqueue_thread = None\n",
    "    self.coord = None\n",
    "    self.coord = tf.train.Coordinator()\n",
    "    self.threads = None\n",
    "    '''\n",
    "    num_samples = self.labels.shape[0]\n",
    "    num_batches = num_samples // batch_size\n",
    "    # last_batch_size = num_samples - num_batches * batch_size\n",
    "    split_conf = [batch_size*(i+1) for i in range(num_batches)]\n",
    "    split_conf.append(num_samples)\n",
    "\n",
    "    self.image_batches = np.split(np.transpose(self.images, (3, 0, 1, 2)), split_conf, axis=0)\n",
    "    self.label_batches = np.split(self.labels, split_conf, axis=0)\n",
    "    '''\n",
    "\n",
    "  def load_dataset(self, session):\n",
    "    start = 0\n",
    "    dataset_size = len(self.labels)\n",
    "    try:\n",
    "      while not self.coord.should_stop():\n",
    "        end = start + self.batch_size\n",
    "        print(\"loading [%d:%d] into input queue...\" % (start, end))\n",
    "        image_batch = self.images[start:end]\n",
    "        label_batch = self.labels[start:end]\n",
    "        start = end\n",
    "        if end >= dataset_size:\n",
    "          self.coord.request_stop()\n",
    "          break\n",
    "        session.run(\n",
    "          self.enqueue, \n",
    "          feed_dict={\n",
    "            self.queue_image : image_batch,\n",
    "            self.queue_label : label_batch})\n",
    "    except Exception as e:\n",
    "      coord.request_stop(e)\n",
    "    print(\"dataset loaded successfully.\")\n",
    "\n",
    "  def preprocess(self):\n",
    "    image, label = self.example_queue.dequeue()\n",
    "    distorted_image = tf.image.random_flip_left_right(image)\n",
    "    distorted_image = tf.image.random_brightness(distorted_image, max_delta=63)\n",
    "    distorted_image = tf.image.random_contrast(distorted_image, lower=0.2, upper=1.8)\n",
    "    float_image = tf.image.per_image_standardization(distorted_image)\n",
    "    return float_image, label\n",
    "\n",
    "  def load_batch(self):\n",
    "    image, label= self.preprocess()\n",
    "    image.set_shape([32, 32, 3])\n",
    "    label.set_shape([1])\n",
    "    image_batch, label_batch = tf.train.shuffle_batch(\n",
    "      [image, label],\n",
    "      batch_size=self.batch_size,\n",
    "      num_threads=4,\n",
    "      capacity=NUM_EXAMPLES_PER_EPOCH_FOR_EVAL + 3 * self.batch_size,\n",
    "      min_after_dequeue=NUM_EXAMPLES_PER_EPOCH_FOR_EVAL) \n",
    "    tf.summary.image('images', image_batch)\n",
    "    return image_batch, tf.reshape(label_batch, [self.batch_size])\n",
    "\n",
    "  def load(self, session):\n",
    "    self.enqueue_thread = threading.Thread(target=self.load_dataset, args=[session])\n",
    "    self.enqueue_thread.isDaemon()\n",
    "    self.enqueue_thread.start()\n",
    "    self.threads = tf.train.start_queue_runners(coord=self.coord, sess=session)\n",
    "    \n",
    "  def close(self, session):\n",
    "    session.run(self.example_queue.close(cancel_pending_enqueues=True))\n",
    "    self.coord.request_stop()\n",
    "    try:\n",
    "      self.coord.join(self.threads)\n",
    "    except Exception as e:\n",
    "      print(\"thread error: \", e)\n",
    "    print(\"dataloader closed successfully.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  fig = plt.figure()\n",
    "  num_plot_cols = NUM_SUBPLOT_COLS\n",
    "  num_plot_rows = int(math.ceil(BATCH_SIZE/num_plot_cols))\n",
    "  labels = []\n",
    "\n",
    "  with tf.Graph().as_default():\n",
    "    dataloader = DataLoader(DATASET_PATH, BATCH_SIZE)\n",
    "    image_batch, label_batch = dataloader.load_batch()\n",
    "    run_options = tf.RunOptions(timeout_in_ms=4000000)\n",
    "    with tf.Session() as session:\n",
    "      dataloader.load(session)\n",
    "      for batch in range(NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN // BATCH_SIZE):\n",
    "        images, labels = session.run([image_batch, label_batch], options=run_options)\n",
    "        print(images.shape, labels.shape)\n",
    "        for batch_i in range(BATCH_SIZE):\n",
    "          sub_plot = fig.add_subplot(num_plot_rows, num_plot_cols, batch_i+1)\n",
    "          plt.imshow(images[batch_i])\n",
    "        labels.append([label[0] for label in label_batch])\n",
    "      dataloader.close(session)\n",
    "  print(labels)\n",
    "  plt.show()\n",
    "  '''\n",
    "  batch_count = 0\n",
    "  fig = plt.figure()\n",
    "  num_plot_cols = NUM_SUBPLOT_COLS\n",
    "  num_plot_rows = int(math.ceil(BATCH_SIZE/num_plot_cols))\n",
    "  labels = []\n",
    "  for image_batch, label_batch in dataloader.iter():\n",
    "    if batch_count > 0:\n",
    "      break\n",
    "    for batch_i in range(BATCH_SIZE):\n",
    "      sub_plot = fig.add_subplot(num_plot_rows, num_plot_cols, batch_i+1)\n",
    "      plt.imshow(image_batch[batch_i])\n",
    "    batch_count += 1\n",
    "    labels.append([label[0] for label in label_batch])\n",
    "\n",
    "  print(labels)\n",
    "  plt.show()\n",
    "  '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
