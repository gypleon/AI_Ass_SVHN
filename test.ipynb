{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "dataloader.py"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading raw file: ./data/test_32x32.mat\n",
      "random validation set [8529:9529]\n",
      "filling input queue\n",
      "loading batch of samples: 1000\n",
      "(1000, 32, 32, 3) (1000,)\n",
      "[1 4 4 4 6 9 9 2 5 4]\n",
      "[8 4 9 6 5 2 0 1 5 4]\n",
      "[3 0 5 5 1 1 6 2 3 5]\n",
      "[2 7 1 4 7 3 1 5 2 1]\n",
      "[6 7 7 6 2 2 2 5 0 1]\n",
      "[8 3 9 1 0 0 2 1 1 2]\n",
      "[8 6 4 0 3 4 5 2 2 1]\n",
      "[1 0 6 3 1 9 0 1 5 6]\n",
      "[6 4 6 5 1 2 5 0 5 6]\n",
      "[6 7 1 7 4 3 3 3 1 2]\n",
      "[2 1 1 1 8 0 0 1 5 6]\n",
      "[3 9 0 2 2 7 5 3 9 9]\n",
      "[9 2 6 2 6 5 6 4 7 7]\n",
      "[1 1 4 2 5 2 7 6 4 0]\n",
      "[3 9 0 1 7 4 2 1 7 3]\n",
      "[5 2 4 1 0 9 7 1 0 7]\n",
      "[5 1 9 6 0 1 2 8 4 7]\n",
      "[0 2 2 7 9 4 2 4 1 7]\n",
      "[1 9 1 2 3 1 3 4 5 1]\n",
      "[7 2 3 6 2 9 7 4 6 8]\n",
      "[8 5 2 3 7 2 7 2 7 0]\n",
      "[7 3 2 1 7 0 0 2 5 2]\n",
      "[4 0 1 8 2 6 3 7 0 1]\n",
      "[7 4 3 3 0 2 5 1 2 0]\n",
      "[4 6 4 1 1 7 3 2 5 2]\n",
      "[2 1 4 4 6 7 3 6 4 1]\n",
      "[2 6 4 1 7 2 3 9 2 1]\n",
      "[2 6 4 0 5 5 8 7 8 5]\n",
      "[2 7 0 6 8 4 9 6 3 4]\n",
      "[2 6 5 8 1 9 0 7 9 4]\n",
      "[6 2 1 2 2 2 7 0 3 1]\n",
      "[5 2 0 1 3 1 6 2 1 3]\n",
      "[1 8 2 0 2 0 1 4 8 4]\n",
      "[4 7 1 3 2 7 3 1 5 6]\n",
      "[2 4 2 0 6 3 2 3 3 7]\n",
      "[2 3 2 4 6 2 2 3 7 1]\n",
      "[2 2 1 5 4 1 4 5 5 1]\n",
      "[0 9 5 5 2 1 6 5 2 3]\n",
      "[0 2 3 6 2 2 0 1 2 1]\n",
      "[9 2 1 7 7 1 9 2 5 0]\n",
      "[3 0 2 2 8 8 8 5 1 1]\n",
      "[4 3 5 9 9 2 5 6 1 2]\n",
      "[5 1 4 1 1 4 3 1 0 0]\n",
      "[4 5 8 4 2 5 0 8 7 1]\n",
      "[1 2 1 0 7 1 8 1 5 9]\n",
      "[2 2 2 9 1 6 2 9 2 3]\n",
      "[7 8 2 1 1 7 6 5 3 3]\n",
      "[1 2 0 1 7 1 5 3 7 6]\n",
      "[1 5 4 2 2 2 8 5 1 6]\n",
      "[0 7 7 5 3 1 2 4 6 2]\n",
      "[9 8 7 4 5 9 1 5 6 1]\n",
      "[6 6 9 6 7 3 2 8 5 1]\n",
      "[5 6 7 8 9 7 9 8 8 5]\n",
      "[7 5 2 2 2 2 2 1 5 3]\n",
      "[0 3 3 4 1 6 7 1 1 4]\n",
      "[4 3 9 7 4 3 5 5 3 2]\n",
      "[6 6 4 2 0 8 3 3 1 1]\n",
      "[9 1 7 3 1 1 3 6 8 1]\n",
      "[3 1 3 5 3 2 9 0 9 7]\n",
      "[1 2 0 8 1 0 1 4 3 2]\n",
      "[3 7 1 1 0 8 3 1 4 1]\n",
      "[0 2 5 5 6 7 8 1 7 7]\n",
      "[3 2 6 3 5 8 6 1 7 9]\n",
      "[5 4 1 6 3 2 1 5 3 5]\n",
      "[4 1 5 0 2 2 8 6 1 1]\n",
      "[0 2 3 1 3 6 0 1 2 9]\n",
      "[1 1 1 9 6 7 7 2 1 2]\n",
      "[1 3 2 4 3 6 2 1 4 2]\n",
      "[7 3 3 4 9 4 7 8 8 1]\n",
      "[8 1 3 3 2 4 7 1 9 2]\n",
      "[3 3 1 9 0 3 9 1 2 7]\n",
      "[1 1 2 1 7 2 5 1 2 1]\n",
      "[9 0 1 5 2 8 1 4 2 4]\n",
      "[2 5 0 0 5 2 1 1 3 4]\n",
      "[3 6 2 8 9 0 4 1 4 7]\n",
      "[2 4 5 1 9 7 2 9 1 8]\n",
      "[2 2 1 4 3 3 2 5 5 6]\n",
      "[2 3 5 7 0 6 2 6 5 1]\n",
      "[1 3 2 2 8 1 1 3 9 3]\n",
      "[7 7 9 8 6 1 1 0 1 6]\n",
      "[2 1 9 1 5 2 7 1 6 4]\n",
      "[3 8 1 7 3 2 3 1 1 2]\n",
      "[3 9 7 3 4 1 8 8 1 4]\n",
      "[9 1 1 2 5 2 5 2 1 3]\n",
      "[1 3 1 8 1 1 7 8 2 9]\n",
      "[1 0 0 1 8 1 6 0 2 1]\n",
      "[6 1 9 9 7 7 6 6 6 1]\n",
      "[2 3 1 0 3 4 8 4 2 6]\n",
      "[4 1 6 7 3 3 7 1 9 1]\n",
      "[6 8 2 6 1 0 1 5 4 1]\n",
      "[0 5 5 7 9 2 2 2 5 7]\n",
      "[3 1 0 1 2 1 7 5 1 8]\n",
      "[7 3 8 4 3 8 3 1 3 7]\n",
      "[3 1 1 5 1 3 0 2 0 1]\n",
      "[1 1 8 7 9 4 1 3 1 0]\n",
      "[0 1 6 3 4 2 2 2 2 1]\n",
      "[2 6 1 5 1 8 9 3 3 5]\n",
      "[5 1 5 7 1 3 0 1 6 9]\n",
      "[0 1 7 1 7 0 2 2 2 1]\n",
      "[8 3 1 5 1 9 5 4 1 2]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import math\n",
    "import os\n",
    "import threading\n",
    "\n",
    "from six.moves import xrange\n",
    "import scipy.io as sio\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# configuration\n",
    "BATCH_SIZE = 100\n",
    "NUM_SUBPLOT_COLS = 10\n",
    "DATASET_PATH = \"../data/train_32x32.mat\"\n",
    "VALID_DATASET_PATH = \"./data/test_32x32.mat\"\n",
    "GEN_TEST_PATH = \"../data/test_images.mat\"\n",
    "CROP_H = 24\n",
    "CROP_W = 24\n",
    "\n",
    "NUM_CLASSES = 10\n",
    "NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN = 73257\n",
    "NUM_EXAMPLES_PER_EPOCH_FOR_EVAL = 1000\n",
    "\n",
    "class DataLoader:\n",
    "  def __init__(self, data_path, batch_size=50, num_valid_samples=None):\n",
    "    print(\"loading raw file:\", data_path)\n",
    "    data = sio.loadmat(data_path)\n",
    "    self.images = data['X']\n",
    "    self.labels = data['y']\n",
    "    self.images = np.transpose(self.images, (3, 0, 1, 2))\n",
    "    self.labels[self.labels==10] = 0\n",
    "    self.num_valid_samples = num_valid_samples\n",
    "    self.batch_size = num_valid_samples or batch_size\n",
    "    if self.num_valid_samples != None:\n",
    "      self.random_valid_set()\n",
    "    # create queue\n",
    "    print(\"filling input queue\")\n",
    "    self.queue_image = tf.placeholder(tf.int64, shape=[self.batch_size, 32, 32, 3], name=\"input_images\")\n",
    "    self.queue_label = tf.placeholder(tf.int64, shape=[self.batch_size, 1], name=\"input_labels\")\n",
    "    self.example_queue = tf.FIFOQueue(\n",
    "      capacity=int(NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN * 0.4) + 3 * self.batch_size,\n",
    "      dtypes=[tf.int64, tf.int64],\n",
    "      shapes=[[32, 32, 3], [1]])\n",
    "    # self.example_queue = tf.train.input_producer(examples)\n",
    "    self.enqueue = self.example_queue.enqueue_many([self.queue_image, self.queue_label])\n",
    "\n",
    "    self.enqueue_thread = None\n",
    "    self.coord = None\n",
    "    self.coord = tf.train.Coordinator()\n",
    "    self.threads = None\n",
    "\n",
    "  def random_valid_set(self):\n",
    "    num_valid_samples = self.num_valid_samples\n",
    "    dataset_size = self.images.shape[0]\n",
    "    start = np.random.randint(0, dataset_size - num_valid_samples)\n",
    "    self.images = self.images[start:start+num_valid_samples]\n",
    "    self.labels = self.labels[start:start+num_valid_samples]\n",
    "    print(\"random validation set [%d:%d]\" % (start, start+num_valid_samples))\n",
    "    \n",
    "  def data_stream(self, session):\n",
    "    start = 0\n",
    "    dataset_size = len(self.labels)\n",
    "    try:\n",
    "      while not self.coord.should_stop():\n",
    "      # while True:\n",
    "        end = start + self.batch_size\n",
    "        # print(\"loading [%d:%d] into input queue...\" % (start, end))\n",
    "        if end <= dataset_size:\n",
    "          image_batch = self.images[start:end]\n",
    "          label_batch = self.labels[start:end]\n",
    "          start = end\n",
    "        else:\n",
    "          remaining = end - dataset_size\n",
    "          image_batch = np.concatenate((self.images[start:dataset_size], self.images[0:remaining]))\n",
    "          label_batch = np.concatenate((self.labels[start:dataset_size], self.labels[0:remaining]))\n",
    "          start = remaining\n",
    "        session.run(\n",
    "          self.enqueue, \n",
    "          feed_dict={\n",
    "            self.queue_image : image_batch,\n",
    "            self.queue_label : label_batch})\n",
    "    except Exception as e:\n",
    "      print(\"DATALOADER ERROR:\", e)\n",
    "      self.coord.request_stop(e)\n",
    "    print(\"data stream closed.\")\n",
    "\n",
    "  def preprocess(self):\n",
    "    image, label = self.example_queue.dequeue()\n",
    "    # distorted_image = tf.random_crop(image, [CROP_H, CROP_w, 3])\n",
    "    if self.num_valid_samples == None:\n",
    "      distorted_image = tf.image.random_flip_left_right(image)\n",
    "      distorted_image = tf.image.random_brightness(distorted_image, max_delta=63)\n",
    "      distorted_image = tf.image.random_contrast(distorted_image, lower=0.2, upper=1.8)\n",
    "    else:\n",
    "      distorted_image = image\n",
    "    float_image = tf.image.per_image_standardization(distorted_image)\n",
    "    return float_image, label\n",
    "\n",
    "  def load_batch(self):\n",
    "    image, label= self.preprocess()\n",
    "    image.set_shape([32, 32, 3])\n",
    "    label.set_shape([1])\n",
    "    if self.num_valid_samples == None:\n",
    "      image_batch, label_batch = tf.train.shuffle_batch(\n",
    "        [image, label],\n",
    "        batch_size=self.batch_size,\n",
    "        num_threads=4,\n",
    "        capacity=int(NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN * 0.4) + 3 * self.batch_size,\n",
    "        min_after_dequeue=int(NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN * 0.4))\n",
    "    else:\n",
    "      image_batch, label_batch = tf.train.batch(\n",
    "        [image, label],\n",
    "        batch_size=self.batch_size,\n",
    "        num_threads=4,\n",
    "        capacity=int(NUM_EXAMPLES_PER_EPOCH_FOR_EVAL * 0.4) + 3 * self.batch_size)\n",
    "\n",
    "    tf.summary.image('images', image_batch)\n",
    "    print(\"loading batch of samples:\", self.batch_size) \n",
    "    return image_batch, tf.reshape(label_batch, [self.batch_size])\n",
    "\n",
    "  def load(self, session):\n",
    "    self.enqueue_thread = threading.Thread(target=self.data_stream, args=[session])\n",
    "    self.enqueue_thread.isDaemon()\n",
    "    self.enqueue_thread.start()\n",
    "    self.threads = tf.train.start_queue_runners(coord=self.coord, sess=session)\n",
    "    \n",
    "  def close(self, session):\n",
    "    session.run(self.example_queue.close(cancel_pending_enqueues=True))\n",
    "    self.coord.request_stop()\n",
    "    try:\n",
    "      self.coord.join(self.threads)\n",
    "    except Exception as e:\n",
    "      print(\"thread error: \", e)\n",
    "    print(\"dataloader closed successfully.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  fig = plt.figure()\n",
    "  num_valid_samples = NUM_EXAMPLES_PER_EPOCH_FOR_EVAL\n",
    "  num_plot_cols = NUM_SUBPLOT_COLS\n",
    "  num_plot_rows = int(math.ceil(num_valid_samples/num_plot_cols))\n",
    "  labels = []\n",
    "\n",
    "  with tf.Graph().as_default():\n",
    "    dataloader = DataLoader(VALID_DATASET_PATH, num_valid_samples=1000)\n",
    "    image_batch, label_batch = dataloader.load_batch()\n",
    "    run_options = tf.RunOptions(timeout_in_ms=4000000)\n",
    "    with tf.Session() as session:\n",
    "      dataloader.load(session)\n",
    "      images, labels = session.run([image_batch, label_batch], options=run_options)\n",
    "      print(images.shape, labels.shape)\n",
    "      for row in range(num_plot_rows):\n",
    "        print(labels[row*num_plot_cols:(row+1)*num_plot_cols])\n",
    "      for batch_i in range(num_valid_samples):\n",
    "        sub_plot = fig.add_subplot(num_plot_rows, num_plot_cols, batch_i+1)\n",
    "        plt.imshow(images[batch_i])\n",
    "      dataloader.close(session)\n",
    "  plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
